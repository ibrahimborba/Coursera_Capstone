{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# IBM CAPSTONE - Analysing Rent Pricing"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Introduction\n\nFor this final project, we're going to tackle the infamous problem of Rent Pricing. Knowing that real estate stakeholders need to be well informed about rent pricing so they can take better decisions, either for finding a place to rent, or to put a property for renting. In this whole renting market, the hospitality has found a new branch in which homeowners rent their house for tourists, for a, usually, cheaper price. However, the real estate is an unstable market, varying a lot on seasonality, random happenings, but mostly, to the surroundings of a property and what it can offer in the vicinities. It is important to have a well established method to evaluate the price of a house/apartment and take a decision based on that value.\n\nSo, our main question will be:\n\n*How does the venues influence the price of an accomodation? Can we predict the price of a home/apartment for renting based on the venues and locations?*\n\nThis question is of interest for both sides of this transaction. The homeowner, who needs to know the best areas and price to put on their property, and the visitor, who will be looking for a balance o price and location.\n\nNow, hence the importance of location, we must pick at least a city to evaluate these prices. For this project, the city will be Rio de Janeiro in Brasil. Being a city with high contrasts like, being the main touristic route in Brasil and hosting a World Cup, but also with high violence ad poverty rates. It will be interesting to investigate how the prices fluctuate in such conditions.\n "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2. Data\n\nIt is a requirement that the Foursquare API is used, so this is one of the Databases that I will be using, specially to retrieve venues and their location. Another dataset that will be useful is the Airbnb dataset provided by their Inside Airbnb, since it is, currently, the bigest platform for C2C renting market. The dataset retrieved for this project was collected on 24 May, 2020."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1 Data Scraping\nImporting the referred libraries and collecting the necessary data. Here I applied a Pandas Copy, so I won't need to load the whole dataset again everytime I screw the database."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\n\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "df_listingsAirbnb = pd.read_csv(\"http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2020-05-24/data/listings.csv.gz\",compression='gzip')\ndf_listingsAirbnb.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_listings = df_listingsAirbnb.copy()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n### 2.2 Knowing and Cleansing the Airbnb Database\nAs expected, the database has values that does not interest the question we asked in the Introduction.\n\nSo the following steps will be taken to make the database more friendly for future EDA and Modelling.\n\nAmong the procedures taken are: selecting features, one-hot enconding, removing outliers"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#knowing our dataset\ndf_listings.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "#removing columns filled with Nan values, irrelevant data like 'id', or a 75% amount equals to '0'\ndf_listings = df_listings[['neighbourhood', 'latitude','longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'square_feet', 'guests_included', 'minimum_nights', 'maximum_nights', 'price']]\ndf_listings.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_listings.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Checking for amount on Nan values in other features. If there is more than 10% of Nan we will drop the column, if not, we will substitute by the mean.\nprint(\"number of NaN values for the column bedrooms :\", df_listings['bedrooms'].isnull().sum())\nprint(\"number of NaN values for the column bathrooms :\", df_listings['bathrooms'].isnull().sum())\nprint(\"number of NaN values for the column beds :\", df_listings['beds'].isnull().sum())\nprint(\"number of NaN values for the column square_feet :\", df_listings['square_feet'].isnull().sum())\nprint(\"number of NaN values for the column guests_included :\", df_listings['guests_included'].isnull().sum())\nprint(\"number of NaN values for the column minimum_nights :\", df_listings['minimum_nights'].isnull().sum())\nprint(\"number of NaN values for the column maximum_nights :\", df_listings['maximum_nights'].isnull().sum())\nprint(\"number of NaN values for the column neighbourhood :\", df_listings['neighbourhood'].isnull().sum())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "mean=df_listings['bedrooms'].mean()\ndf_listings['bedrooms'].replace(np.nan,mean, inplace=True)\n\nmean=df_listings['bathrooms'].mean()\ndf_listings['bathrooms'].replace(np.nan,mean, inplace=True)\n\nmean=df_listings['beds'].mean()\ndf_listings['beds'].replace(np.nan,mean, inplace=True)\n\ndf_listings.drop(['square_feet'], axis=1, inplace = True)\n\ndf_listings.dropna(axis=0, inplace = True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_listings.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# building a function to convert price to float so it can be used as a target\ndef convert_currency(val):\n    \"\"\"\n    Convert the string number value to a float\n     - Remove $\n     - Remove commas\n     - Convert to float type\n    \"\"\"\n    new_val = val.replace(',','').replace('$', '')\n    return float(new_val)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "df_listings['price'] = df_listings['price'].apply(convert_currency)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.3 Using the Foursquare API"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Rio de Janeiro'\n\ngeolocator = Nominatim(user_agent=\"rj_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Rio de Janeiro are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Getting Top 500 venues in a 1000 meters radius\nLIMIT = 100 \nradius = 500\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    latitude, \n    longitude, \n    radius, \n    LIMIT)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "results = requests.get(url).json()\nresults"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "nearby_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#slicing the dataframe so i can run the query with my sand account\ndf_listingsSample = df_listings.sample(100)\ndf_listingsSample.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "rJ_venues = getNearbyVenues(names=df_listingsSample['neighbourhood'],\n                                   latitudes=df_listingsSample['latitude'],\n                                   longitudes=df_listingsSample['longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(rJ_venues.shape)\nrJ_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Methodology\n\nNow that we have our database with both the Airbnb and Foursquare API, we will do through EDA, Modelling and Model Evaluation. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.1 Exploratory Data Analysis\n\nImporting the necessary libraries. We will use Scatterplots, Heatmaps and Geospatial Visualization, so we can understand better how the features relate to our target *price*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import seaborn as sns\nimport matplotlib.pyplot as plt"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from pandas.plotting import scatter_matrix\n\ncontinuous_cols = [\"bedrooms\",\"bathrooms\",\"beds\",\"guests_included\",\"minimum_nights\",\"maximum_nights\", \"price\"]\nscatter_matrix(df_listings.sample(1000)[continuous_cols], figsize=(15, 10))\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tmp = df_listings.groupby('neighbourhood')['price'].sum().sort_values(ascending = False)\nplt.figure(figsize=(30,6))\n_ = tmp.plot(kind='bar')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.figure(figsize=(20,5))\nx_data, y_data = (df_listings[\"neighbourhood\"].values, df_listings[\"price\"].values)\nplt.plot(x_data, y_data, 'ro')\nplt.ylabel('Price')\nplt.xlabel('Neighbourhood')\nplt.xticks(rotation=90)\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3.2 Modelling and Evaluating\n\nSince this a regression problem and we are dealing with a distribution that, taken the outliers, could be linear, we will try a polynomial regression."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.2.1 Regression\n\nSince we are trying to predict price, this is a Regression problem. We will use the Statsmodel package. Its a very extensive package that allow us to implement different types of regression, displays the features by weight, treats categorical features and prints a series of evaluations."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import statsmodels.formula.api as smf\nimport sklearn, matplotlib, statsmodels"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "results = smf.ols('price ~ accommodates + np.square(bedrooms) + np.square(bathrooms) + np.square(beds) + guests_included + minimum_nights + maximum_nights + C(neighbourhood)', data=df_listings).fit()\nresults.summary()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.2.1 Clustering\n\nOur model didn't perform so well with regression. Lets try clustering so we can better visualize the inflence of location in a rent price."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\nrJ_onehot = pd.get_dummies(rJ_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nrJ_onehot['Neighborhood'] = rJ_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [rJ_onehot.columns[-1]] + list(rJ_onehot.columns[:-1])\nrJ_onehot = rJ_onehot[fixed_columns]\n\nrJ_onehot.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rJ_grouped = rJ_onehot.groupby('Neighborhood').mean().reset_index()\nrJ_grouped.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = rJ_grouped['Neighborhood']\n\nfor ind in np.arange(rJ_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(rJ_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Seting number of clusters\nkclusters = 5\n\nrJ_grouped_clustering = rJ_grouped.drop('Neighborhood', 1)\n\n# Run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(rJ_grouped_clustering)\n\n# Check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nrJ_merged = df_listings\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nrJ_merged = rJ_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='neighbourhood')\n\nrJ_merged.head() # check the last columns!"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rJ_merged.dropna(axis = 0, inplace = True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(rJ_merged['latitude'], rJ_merged['longitude'], rJ_merged['neighbourhood'], rJ_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[int(cluster-1)],\n        fill=True,\n        fill_color=rainbow[int(cluster-1)],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rJ_merged.loc[rJ_merged['Cluster Labels'] == 0, rJ_merged.columns[[1] + list(range(5, rJ_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rJ_merged.loc[rJ_merged['Cluster Labels'] == 1, rJ_merged.columns[[1] + list(range(5, rJ_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Results\n\nAfter analysing the results in EDA and the Models, it became clear that we can use location as an important feature to predict rent pricing, since it represents a significant weight in price variation, whilst other variables have an influence, but are not as sensible.\n\nFor Modeling, it's better to implement more complex models. Since the relation between location and price is not linear, and requires more versatile models."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Discussion\n\nIt can be recommended for owners to try and rent properties in costal areas, as they are better valued and can generate more revenue.\n\nFor tourists, if they don't have a problem with price, than the costal area is the most recommended, as it has a higher concentration of venues. However, if one is trying to save, it can still find properties close to costal areas but are not as expensive."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Conclusion\n\nAfer analysing these datas. It is clear that we can predict rent price using location and venues. The following model is a first attemp and can be better improvef through more Feature Engineering and trying to implement other models that can better access these problem."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}